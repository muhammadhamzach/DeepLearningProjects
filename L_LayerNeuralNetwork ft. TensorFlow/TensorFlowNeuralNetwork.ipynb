{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bea1GYfIMK0K"
   },
   "source": [
    "# Neural Networks Using Tensorflow (Basics)\n",
    "This notebook is based on the deeplearning.ai Hyper-parameter course's Week 3 Lab.\n",
    "* Made by: Muhammad Hamza\n",
    "* Github: muhammadhamzach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBySTiujMawM"
   },
   "source": [
    "Importing the necessary libraries including Tensorflow v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8oh46VrjrZ6P"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SN6dNOEO6lU"
   },
   "source": [
    "### Loading Dataset\n",
    "We load the dataset from the same directory. The two files loaded are for both training and test sets.\n",
    "As usual you flatten the image dataset, then normalize it by dividing by 255. On top of that, you will convert each label to a one-hot vector as shown in Figure 1. Run the cell below to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2z7Ljl9sIh2"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    # Flatten the training and test images\n",
    "    X_train_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "    X_test_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "    \n",
    "    # Normalize image vectors\n",
    "    X_train = X_train_flatten/255.\n",
    "    X_test = X_test_flatten/255.\n",
    "    # Convert training and test labels to one hot matrices\n",
    "    Y_train = convert_to_one_hot(train_set_y_orig, classes.shape[0])\n",
    "    Y_test = convert_to_one_hot(test_set_y_orig, classes.shape[0])\n",
    "    \n",
    "    return X_train, Y_train,X_test, Y_test, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q--5CjAMNDFX"
   },
   "source": [
    "### Using One Hot encodings\n",
    "This is a \"one hot\" encoding i.e. in the converted representation exactly one element of each column is \"hot\" (meaning set to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKhP_9Dgr5Qa"
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    \n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGs1FapIOOcw"
   },
   "source": [
    "### Create placeholders\n",
    "\n",
    "Now to create placeholders for `X` and `Y`. This will allow you to later pass your training data in when you run your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FE4tkXVr-MF"
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    ##Creates the placeholders for the tensorflow session.\n",
    "\n",
    "    X = tf.compat.v1.placeholder(tf.float32, [n_x, None], name=\"X\")\n",
    "    Y = tf.compat.v1.placeholder(tf.float32, [n_y, None], name=\"Y\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6q6ePXkP9eb"
   },
   "source": [
    "### Mini-Batch Gradient descent\n",
    "\n",
    "Let's learn how to build mini-batches from the training set (X, Y).\n",
    "\n",
    "There are two steps:\n",
    "- **Shuffle**: Create a shuffled version of the training set (X, Y) as shown below. Each column of X and Y represents a training example. Note that the random shuffling is done synchronously between X and Y. Such that after the shuffling the $i^{th}$ column of X is the example corresponding to the $i^{th}$ label in Y. The shuffling step ensures that examples will be split randomly into different mini-batches. \n",
    "\n",
    "- **Partition**: Partition the shuffled (X, Y) into mini-batches of size `mini_batch_size`. Note that the number of training examples is not always divisible by `mini_batch_size`. The last mini batch might be smaller, but you don't need to worry about this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7etQcQ0VsNTn"
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):    \n",
    "    #Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4B8b2MHeOZgT"
   },
   "source": [
    "### Initializing the parameters\n",
    "\n",
    "Next task is to initialize the parameters in tensorflow. Implement the function below to initialize the parameters in tensorflow. You are going use Xavier Initialization for weights and Zero Initialization for biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xZs9yhlvsFgs"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    ## Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "\n",
    "    tf.compat.v1.random.set_random_seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        \n",
    "        parameters['W' + str(l)] = tf.compat.v1.get_variable('W' + str(l), [layer_dims[l],layer_dims[l-1]], initializer = tf.keras.initializers.GlorotUniform(seed = 1))\n",
    "        parameters['b' + str(l)] = tf.compat.v1.get_variable('b' + str(l), [layer_dims[l], 1], initializer = tf.zeros_initializer())\n",
    "        np.zeros((layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLknIgBGNaVe"
   },
   "source": [
    "### Computing the Cost\n",
    "\n",
    "You can also use a built-in function to compute the cost of your neural network. So instead of needing to write code to compute this as a function of $a^{[2](i)}$ and $y^{(i)}$ for i=1...m: \n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\$$\n",
    "\n",
    "you can do it in one line of code in tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-deu9eLQr7nu"
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z, Y):\n",
    "    # Computes the cost\n",
    "\n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRXRs7rvPOyJ"
   },
   "source": [
    "### Forward propagation in tensorflow \n",
    "\n",
    "You will now implement the forward propagation module in tensorflow. The function will take in a dictionary of parameters and it will complete the forward pass. It is important to note that the forward propagation stops at `Z`. The reason is that in tensorflow the last linear layer output is given as input to the function computing the loss. Therefore, you don't need `AL`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WgpsurEsAed"
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    ##Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "\n",
    "    A = X\n",
    "    L = len(parameters) // 2  \n",
    "    \n",
    "    tf.compat.v1.random.set_random_seed(1)\n",
    "      \n",
    "    for l in range(1, L+1):     \n",
    "        Z = tf.add(tf.matmul(parameters['W'+str(l)],A),parameters['b'+str(l)])\n",
    "        if l != L:\n",
    "            A = tf.nn.relu(Z)\n",
    " \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEUtXFmOPzwS"
   },
   "source": [
    "### Predictions\n",
    "\n",
    "Use your model to predict by building predict().\n",
    "Use forward propagation to predict results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7elrYMqsLEW"
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    params = {}\n",
    "    L = len(parameters) // 2 \n",
    "    \n",
    "    for l in range(1, L):    \n",
    "        params['W' + str(l)] = tf.convert_to_tensor(parameters['W' + str(l)])\n",
    "        params['b' + str(l)] = tf.convert_to_tensor(parameters['b' + str(l)])\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [X.shape[0], 1])\n",
    "    \n",
    "    Z = forward_propagation(x, params)\n",
    "    p = tf.argmax(Z)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxGbbN1_QvA3"
   },
   "source": [
    "### Building the model\n",
    "\n",
    "Now, we will bring it all together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWAI3331vyDp"
   },
   "outputs": [],
   "source": [
    "def tensor_model(X_train, Y_train, X_test, Y_test, layer_dims, optimizer=\"gd\", beta1= 0.9, beta2=0.999, epsilon=1e-8, learning_rate = 0.0001,num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    ##Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.compat.v1.random.set_random_seed(1)\n",
    "    seed = 3                                         \n",
    "    (n_x, m) = X_train.shape                          \n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    if optimizer == \"gd\":\n",
    "        optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate, beta1=beta1, beta2=beta2, epsilon = epsilon).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0\n",
    "            #num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                #The line that runs the graph on a minibatch.\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / minibatch_size\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.figure(1)\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per fives)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        parameters = sess.run(parameters)\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5Vi6XH2Qz1g"
   },
   "source": [
    "### Main Function\n",
    "Here we will call our Neural Network made using Tensor Flow and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "LQP8sBPNv3KP",
    "outputId": "b7ce8443-50ba-460f-b468-db16d3269610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Muhammad Hamza\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Cost after epoch 0: 1.924667\n",
      "Cost after epoch 100: 0.766357\n",
      "Cost after epoch 200: 0.527253\n",
      "Cost after epoch 300: 0.365863\n",
      "Cost after epoch 400: 0.236924\n",
      "Cost after epoch 500: 0.146674\n",
      "Cost after epoch 600: 0.094273\n",
      "Cost after epoch 700: 0.067775\n",
      "Cost after epoch 800: 0.033554\n",
      "Cost after epoch 900: 0.019139\n",
      "Cost after epoch 1000: 0.011892\n",
      "Cost after epoch 1100: 0.006809\n",
      "Cost after epoch 1200: 0.006445\n",
      "Cost after epoch 1300: 0.003129\n",
      "Cost after epoch 1400: 0.002760\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.85833335\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, classes = load_dataset()\n",
    "m = X_train.shape[1]\n",
    "\n",
    "layer_dims = [X_train.shape[0], 25, 12, classes.shape[0]]  #dimesions of the neural network layer\n",
    "learning_rate = 0.0001                      #alpha learning rate of the system\n",
    "num_epochs = 1500                           #number of iterations \n",
    "minibatch_size = 32                         #use m for Batch Gradient Descent instead of Mini Batch Gradient Descent\n",
    "\n",
    "optimizer = \"adam\"                            #gradient descent type (\"gd\" or \"adam\" available)\n",
    "beta1 = 0.9                                 #momentum parameter for Adam Optimizer\n",
    "beta2 = 0.999                               #momentum parameter for Adam Optimizer\n",
    "epsilon=10e-8                               #for Adam Optimizer\n",
    "\n",
    "\n",
    "parameters = tensor_model(X_train, Y_train, X_test, Y_test, layer_dims, optimizer, beta1,beta2,epsilon, learning_rate, num_epochs, minibatch_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlowNeuralNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
